You have given a file named spark6/user.csv

user.csv
id,topic,hits
Rahul,scala,120
Nikita,spark,80
Mithun,spark,1
myself,cca175,180

Now write a Spark code in scala which will remove the header part and create RDD of values as below, for all rows. And also if id is "myself" than filter out row.
Map(id -> om, topic -> scala, hits -> 120)

val user  	= sc.textFile("/user/cloudera/spark6/user.csv")
val userRDD = user.map(x => x.split(","))
val header  = userRDD.first
val rows    = userRDD.filter(_(0) != header(0))
rows.take(10)foreach(println)

# split to Map (header/value pairs)
val maps = rows.map(splits => header.zip(splits).toMap)

val results = maps.filter(map => map("id") != "myself")
results.saveAsTextFile("/user/cloudera/spark6/result.txt")