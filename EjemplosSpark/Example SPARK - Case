You have been given two files

spark16/file1.txt
1,9,5
2,7,4
3,8,3

spark16/file2.txt
1,g,h
2,i,j
3,k,l

Load these two files as Spark RDD and join them to produce the below results
(1, ((9,5), (g,h)))
(2, ((7,4), (i,j)))
(3, ((8,3), (k,l)))

And write code snippet which will sum the second columns of above joined results (5+4+3)

val file1RDD = sc.textFile("/user/cloudera/spark16/file1.txt").map(x => (x.split(',')(0),(x.split(',')(1),x.split(',')(2))))
val file2RDD = sc.textFile("/user/cloudera/spark16/file2.txt").map(x => (x.split(',')(0),(x.split(',')(1),x.split(',')(2))))

val joined   = file1RDD.join(file2RDD)
val sum		 = joined.map{case (_,((_,num2),(_,_))) => num2.toInt}.reduce(_+_)
